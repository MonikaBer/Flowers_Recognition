{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9865d6fed827484faacea5b29eb13491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ea0c30da47448b7849db7355caa8092",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f5cf82402d442c0b09843b441792995",
              "IPY_MODEL_9ce5cc474d69497e9dfde96a56d48b77"
            ]
          }
        },
        "5ea0c30da47448b7849db7355caa8092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f5cf82402d442c0b09843b441792995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5f65a225641f41e7a4427311d7c5a028",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5439c6fd748348a0a226e60364bb450d"
          }
        },
        "9ce5cc474d69497e9dfde96a56d48b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f15a909250ab413d9da08bf193821a3b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:08&lt;00:00, 11.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c30a4c5afadc4f3c949eefacab3dcaf0"
          }
        },
        "5f65a225641f41e7a4427311d7c5a028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5439c6fd748348a0a226e60364bb450d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f15a909250ab413d9da08bf193821a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c30a4c5afadc4f3c949eefacab3dcaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jizUBoeUww1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch==1.5.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFS3NogxzlXL",
        "colab_type": "code",
        "outputId": "2350a4c3-dd97-4db2-8145-9ed576deafa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMbi3eaR1kXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = 'gdrive/My Drive/flowers'  #change dir to your project folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoKHPvlH8fhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96jkQPJj8k_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torch import nn, device, optim\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics as stat\n",
        "import math\n",
        "%matplotlib inline\n",
        "\n",
        "data_dir = root_path\n",
        "num_classes = 5\n",
        "batch_size = 5\n",
        "num_epochs = 15\n",
        "# In feature extraction, we start with a pretrained model and only update the final layer weights from which we derive\n",
        "# predictions. \n",
        "# It is called feature extraction because we use the pretrained CNN as a fixed feature-extractor, and only change \n",
        "# the output layer.\n",
        "feature_extract = True\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxTwmrQECCEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quadratic(input, weight, bias=None):\n",
        "    # type: (Tensor, Tensor, Optional[Tensor]) -> Tensor\n",
        "    tens_ops = (input, weight)\n",
        "    if not torch.jit.is_scripting():\n",
        "        if any([type(t) is not torch.Tensor for t in tens_ops]) and nn.functional.has_torch_function(tens_ops):\n",
        "            return nn.functional.handle_torch_function(linear, tens_ops, input, weight, bias=bias)\n",
        "    if input.dim() == 2 and bias is not None:\n",
        "        # fused op is marginally faster\n",
        "\n",
        "        ret = torch.addmm(bias, input, weight.t())\n",
        "        #out = nn.functional.normalize(torch.exp(ret))\n",
        "        out = nn.functional.normalize(torch.pow(ret, 2))\n",
        "        norm = ((2*out) -1 )* 10\n",
        "        \n",
        "        # weights = torch.transpose(weight.t(), 0, 1)\n",
        "        \n",
        "        # sub = torch.sub(input, weights)\n",
        "        # #norm = torch.norm(sub, dim=1)\n",
        "        # #matrix_norm = torch.unsqueeze(norm,1).repeat(1,num_classes)\n",
        "        # #print(matrix_norm)\n",
        "        # gamma = - 1/2\n",
        "        # arg = torch.mul(sub, gamma)\n",
        "        \n",
        "        # exp = torch.exp(arg[:, :num_classes])\n",
        "        # out = nn.functional.normalize(exp, dim=0)\n",
        "        # norm = ((2*out) -1 )* 10\n",
        "        # #norm = torch.transpose(norm, 0, 1)\n",
        "        ret = norm\n",
        "    else:\n",
        "        print(\"else branch\")\n",
        "        output = input.matmul(weight.t())\n",
        "        if bias is not None:\n",
        "            output += bias\n",
        "        ret = output\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGrF4-TTBpjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Quadratic(nn.Module):\n",
        "    __constants__ = ['in_features', 'out_features']\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(Quadratic, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            nn.init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return quadratic(input, self.weight, self.bias)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return 'in_features={}, out_features={}, bias={}'.format(\n",
        "            self.in_features, self.out_features, self.bias is not None\n",
        "        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY7VHVuC811N",
        "colab_type": "code",
        "outputId": "7e23dcd4-d80d-4714-af83-2699a1d4ceb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "9865d6fed827484faacea5b29eb13491",
            "5ea0c30da47448b7849db7355caa8092",
            "6f5cf82402d442c0b09843b441792995",
            "9ce5cc474d69497e9dfde96a56d48b77",
            "5f65a225641f41e7a4427311d7c5a028",
            "5439c6fd748348a0a226e60364bb450d",
            "f15a909250ab413d9da08bf193821a3b",
            "c30a4c5afadc4f3c949eefacab3dcaf0"
          ]
        }
      },
      "source": [
        "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    torch.manual_seed(10)\n",
        "    model_ft = models.resnet50(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = Quadratic(num_ftrs, num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "def train_model(model, dataloaders, optimizer, criterion, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                \n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs) \n",
        "                        labels_2d = torch.unsqueeze(labels,1).repeat(1,num_classes)\n",
        "                        loss = criterion(outputs, labels_2d)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n",
        "\n",
        "\n",
        "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9865d6fed827484faacea5b29eb13491",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvDNkgXr9UkZ",
        "colab_type": "code",
        "outputId": "ca2637f5-2bb7-4c78-f593-0fb4dcaf80c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "\n",
        "# Setup the loss fxn\n",
        "criterion = nn.MultiLabelMarginLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict,optimizer_ft, criterion, num_epochs=num_epochs, is_inception=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 4.0047 Acc: 0.5516\n",
            "val Loss: 0.8731 Acc: 0.7933\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 1.1857 Acc: 0.7098\n",
            "val Loss: 0.6631 Acc: 0.8400\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 1.0423 Acc: 0.7465\n",
            "val Loss: 0.5912 Acc: 0.8267\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 1.0561 Acc: 0.7492\n",
            "val Loss: 0.5538 Acc: 0.8467\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.9739 Acc: 0.7640\n",
            "val Loss: 0.6563 Acc: 0.8600\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.9955 Acc: 0.7604\n",
            "val Loss: 0.6023 Acc: 0.8400\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.8900 Acc: 0.7739\n",
            "val Loss: 0.5404 Acc: 0.8533\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.9016 Acc: 0.7811\n",
            "val Loss: 0.4646 Acc: 0.8667\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.9300 Acc: 0.7722\n",
            "val Loss: 0.4404 Acc: 0.8733\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.8526 Acc: 0.7827\n",
            "val Loss: 0.6182 Acc: 0.8533\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.9097 Acc: 0.7724\n",
            "val Loss: 0.4797 Acc: 0.8800\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.8641 Acc: 0.7835\n",
            "val Loss: 0.4762 Acc: 0.8667\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.8483 Acc: 0.7935\n",
            "val Loss: 0.5083 Acc: 0.8600\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.8358 Acc: 0.7923\n",
            "val Loss: 0.4173 Acc: 0.8800\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.8571 Acc: 0.7897\n",
            "val Loss: 0.5112 Acc: 0.8600\n",
            "\n",
            "Training complete in 15m 17s\n",
            "Best val Acc: 0.880000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbhV8HzxFd_q",
        "colab_type": "code",
        "outputId": "f23b0411-6dbd-4826-ad71-2a0d76012182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "torch.save(model_ft, 'svm_trained_model.pt')\n",
        "#model_ft = torch.load('gdrive/My Drive/training outcome/trained_model.pt')\n",
        "#model_ft = torch.load('gdrive/My Drive/training outcome/trained_model.pt', map_location=torch.device('cpu'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Quadratic. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icZp-4UkRu56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 224\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Send the model to GPU\n",
        "#model_ft = model_ft.to(device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "image_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform)\n",
        "\n",
        "train_dataset = torch.utils.data.DataLoader(\n",
        "        image_dataset, shuffle=False, num_workers=16\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2w31ld41757",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model_ft.eval()\n",
        "all_features = []\n",
        "\n",
        "for data, target in train_dataset:\n",
        "  out = model_ft(data)\n",
        "  all_features.append(out.detach().numpy())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS-7r03PSPAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(torch.tensor(all_features), \"val_features_tensor.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXxvlQZmPUMw",
        "colab_type": "code",
        "outputId": "13d02a0e-2b21-4ffe-ea71-2b9a26170bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "features_dir = \"gdrive/My Drive/training outcome/\"\n",
        "t = torch.load(features_dir +'all_features_tensor.pt').cpu()\n",
        "X_train = t.detach().numpy().reshape((4170, 2048))\n",
        "\n",
        "t = torch.load(features_dir +'val_features_tensor.pt').cpu()\n",
        "X_test = t.detach().numpy().reshape((150, 2048))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4170, 2048)\n",
            "(150, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xm6zZbjl5eu",
        "colab_type": "code",
        "outputId": "5cc3ce2a-40f8-43eb-9d37-3e4d32581925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "daisy_dir = data_dir + '/train/daisy'\n",
        "daisy_len= len([name for name in os.listdir(daisy_dir) if os.path.isfile(os.path.join(daisy_dir, name))])\n",
        "print(daisy_len)\n",
        "daisy_list = ['daisy'] * daisy_len\n",
        "\n",
        "dandelion_dir = data_dir + '/train/dandelion'\n",
        "dandelion_len= len([name for name in os.listdir(dandelion_dir) if os.path.isfile(os.path.join(dandelion_dir, name))])\n",
        "print(dandelion_len)\n",
        "dandelion_list = ['dandelion'] * dandelion_len\n",
        "\n",
        "rose_dir = data_dir + '/train/rose'\n",
        "rose_len= len([name for name in os.listdir(rose_dir) if os.path.isfile(os.path.join(rose_dir, name))])\n",
        "print(rose_len)\n",
        "rose_list = ['rose'] * rose_len\n",
        "\n",
        "sunflower_dir = data_dir + '/train/sunflower'\n",
        "sunflower_len= len([name for name in os.listdir(sunflower_dir) if os.path.isfile(os.path.join(sunflower_dir, name))])\n",
        "print(sunflower_len)\n",
        "sunflower_list = ['sunflower'] * sunflower_len\n",
        "\n",
        "tulip_dir = data_dir + '/train/tulip'\n",
        "tulip_len= len([name for name in os.listdir(tulip_dir) if os.path.isfile(os.path.join(tulip_dir, name))])\n",
        "print(tulip_len)\n",
        "tulip_list = ['tulip'] * tulip_len\n",
        "\n",
        "y_train = np.concatenate([daisy_list, dandelion_list, rose_list, sunflower_list, tulip_list])\n",
        "\n",
        "#print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "736\n",
            "1022\n",
            "754\n",
            "704\n",
            "954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S25IX-8SbQt4",
        "colab_type": "code",
        "outputId": "b736279b-5fa8-484c-d901-5553e67403f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "daisy_dir = data_dir + '/val/daisy'\n",
        "daisy_len= len([name for name in os.listdir(daisy_dir) if os.path.isfile(os.path.join(daisy_dir, name))])\n",
        "#print(daisy_len)\n",
        "daisy_list = ['daisy'] * daisy_len\n",
        "\n",
        "dandelion_dir = data_dir + '/val/dandelion'\n",
        "dandelion_len= len([name for name in os.listdir(dandelion_dir) if os.path.isfile(os.path.join(dandelion_dir, name))])\n",
        "#print(dandelion_len)\n",
        "dandelion_list = ['dandelion'] * dandelion_len\n",
        "\n",
        "rose_dir = data_dir + '/val/rose'\n",
        "rose_len= len([name for name in os.listdir(rose_dir) if os.path.isfile(os.path.join(rose_dir, name))])\n",
        "#print(rose_len)\n",
        "rose_list = ['rose'] * rose_len\n",
        "\n",
        "sunflower_dir = data_dir + '/val/sunflower'\n",
        "sunflower_len= len([name for name in os.listdir(sunflower_dir) if os.path.isfile(os.path.join(sunflower_dir, name))])\n",
        "#print(sunflower_len)\n",
        "sunflower_list = ['sunflower'] * sunflower_len\n",
        "\n",
        "tulip_dir = data_dir + '/val/tulip'\n",
        "tulip_len= len([name for name in os.listdir(tulip_dir) if os.path.isfile(os.path.join(tulip_dir, name))])\n",
        "#print(tulip_len)\n",
        "tulip_list = ['tulip'] * tulip_len\n",
        "\n",
        "y_test = np.concatenate([daisy_list, dandelion_list, rose_list, sunflower_list, tulip_list])\n",
        "\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffbPC8NWf0xI",
        "colab_type": "code",
        "outputId": "fefcedc9-70f4-4a40-99f5-129d24254fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "#https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/\n",
        "\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(X_train, y_train)\n",
        "y_pred = svclassifier.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[29  0  0  0  1]\n",
            " [ 4 25  0  1  0]\n",
            " [ 0  1 27  0  2]\n",
            " [ 0  1  0 29  0]\n",
            " [ 0  0  2  0 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       daisy       0.88      0.97      0.92        30\n",
            "   dandelion       0.93      0.83      0.88        30\n",
            "        rose       0.93      0.90      0.92        30\n",
            "   sunflower       0.97      0.97      0.97        30\n",
            "       tulip       0.90      0.93      0.92        30\n",
            "\n",
            "    accuracy                           0.92       150\n",
            "   macro avg       0.92      0.92      0.92       150\n",
            "weighted avg       0.92      0.92      0.92       150\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}